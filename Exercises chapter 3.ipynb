{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c71a4a",
   "metadata": {},
   "source": [
    "**Leer el CSV del ejemplo del cap2 y obtener la estructura del schema dado por \n",
    "defecto.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda4a2c",
   "metadata": {},
   "source": [
    "*Python*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0334c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a59373",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"PythonMnMCount\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336b5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm =\"C:/Users/nerea.gomez/Documents/Documentacion/Learning Spark/Datasets/mnm_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8665cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm_df = (spark.read.format(\"csv\")\n",
    " .option(\"header\", \"true\")\n",
    " .option(\"inferSchema\", \"true\")\n",
    " .load(mnm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd64651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(State,StringType,true),StructField(Color,StringType,true),StructField(Count,IntegerType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnm_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa24306",
   "metadata": {},
   "source": [
    "*Scala*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda963bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002836.bosonit.local:4044\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1622800123979)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.functions._\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be408fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@17b4ceb\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "        .builder\n",
    "        .appName(\"MnMCount\")\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43a3c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnmFile: String = C:/Users/nerea.gomez/Documents/Documentacion/Learning Spark/Datasets/mnm_dataset.csv\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Indicamos la ruta de nuestro conjunto de datos\n",
    "val mnmFile = \"C:/Users/nerea.gomez/Documents/Documentacion/Learning Spark/Datasets/mnm_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7432a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnmDF: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Leemos el dataset\n",
    "val mnmDF = spark.read.format(\"csv\")\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .load(mnmFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c6c285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(StructField(State,StringType,true), StructField(Color,StringType,true), StructField(Count,IntegerType,true))\r\n"
     ]
    }
   ],
   "source": [
    "println(mnmDF.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f70393",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1bfa9",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a04332",
   "metadata": {},
   "source": [
    "**Cuando se define un schema al definir un campo por ejemplo StructField('Delay', \n",
    "FloatType(), True) ¿qué significa el último parámetro Boolean?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286d6a1",
   "metadata": {},
   "source": [
    "El parametro booleano indica si esa variable va a admitir valores nulos (true) o no los va admitir(false)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d38898d",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68dd107",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f441d",
   "metadata": {},
   "source": [
    "**Dataset vs DataFrame (Scala). ¿En qué se diferencian a nivel de código?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f2a5a",
   "metadata": {},
   "source": [
    "*Dataset*   \n",
    "    - Para definir el esquema utilizamos la función case class seguida del nombre del esquema y (conjunto de claves valor).    \n",
    "    - Para definir el dataset creamos una variable, leemos lael parámetro .as[nombre_esquema].     \n",
    "\n",
    "    val ds = spark.read   \n",
    "    .json(\"C:/Users/nerea.gomez/Documents/Documentacion/Learning Spark/Datasets/iot_devices.json\")   \n",
    "    .as[DeviceIoTData]  \n",
    "\n",
    "    \n",
    "*DataFrame*     \n",
    "    - Para definir el esquema creamos una variable e introducimos la funcion StructType(Array(StructFile(...), StructFile(..))    \n",
    "    - Para definir el DataFrame leemos la ruta donde se encuentra el archivo y en una nueva variable a partir de la funcion spark.read.schema(nombre_esquema) introducimos el esquema de los datos y con el parametro .csv/txt/parquet...(nombre variable con la ruta de dataset)   \n",
    "    \n",
    "    val fireDF = spark.read.schema(fireSchema)   \n",
    "    .option(\"header\", \"true\")   \n",
    "    .csv(sfFireFile) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0e80f",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c2398",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903e7d0",
   "metadata": {},
   "source": [
    "**Utilizando el mismo ejemplo utilizado en el capítulo para guardar en parquet y \n",
    "guardar los datos en los formatos:   \n",
    "i. JSON   \n",
    "ii. CSV (dándole otro nombre para evitar sobrescribir el fichero origen)   \n",
    "iii. AVRO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd071af",
   "metadata": {},
   "source": [
    "    val csvPath = dataframe\n",
    "    csvPath.write.format(\"csv\").save(\"archivo_csv\")\n",
    "    \n",
    "    otra opcion   \n",
    "    val pruebacsv = spark.read.format(\"csv\"). load(\"nombre_Dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee1402",
   "metadata": {},
   "source": [
    "    val jsonPath = dataframe\n",
    "    jsonPath.write.format(\"json\").save(\"archivo_json\")\n",
    "    \n",
    "    otra opcion   \n",
    "    val pruebajson = spark.read.format(\"json\"). load(\"nombre_Dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb1db3",
   "metadata": {},
   "source": [
    "    val avroPath = dataframe\n",
    "    avroPath.write.format(\"avro\").save(\"archivo_avro\")\n",
    "    \n",
    "    otra opcion   \n",
    "    val pruebavro = spark.read.format(\"avro\"). load(\"nombre_Dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ff167",
   "metadata": {},
   "source": [
    "    para reescribir archivos   \n",
    "    df.write.format(\"formato\").mode(\"overwrite\").save(\"nombredoc\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785b3bd",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4ad89",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e1373",
   "metadata": {},
   "source": [
    "**Revisar al guardar los ficheros (p.e. json, csv, etc) el número de ficheros \n",
    "creados, revisar su contenido para comprender (constatar) como se guardan.   \n",
    "i. ¿A qué se debe que hayan más de un fichero?   \n",
    "ii. ¿Cómo obtener el número de particiones de un DataFrame?   \n",
    "iii. ¿Qué formas existen para modificar el número de particiones de un \n",
    "DataFrame?   \n",
    "iv. Llevar a cabo el ejemplo modificando el número de particiones a 1 y \n",
    "revisar de nuevo el/los ficheros guardados.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f9a52",
   "metadata": {},
   "source": [
    "i. Se debe a que se guardan 8 particiones del DataFrame    \n",
    "ii. DataFrame.rdd.getNumPartitions    \n",
    "iii y iv.   \n",
    "dataframe.repartition(1)   \n",
    "     .write    \n",
    "     .format(\"formato\")  \n",
    "     .mode(\"overwrite\")   \n",
    "     .save(\"nombre_archivo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
